services:
  backend: &backend-common
    build: backend
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/ping"]
      interval: 5s
      timeout: 3s
      retries: 3
    environment:
      - DB_USERNAME=${DB_USERNAME:-postgres}
      - DB_PASSWORD=${DB_PASSWORD:-postgres}
      - DB_HOST=${DB_HOST:-postgres}
      - DB_PORT=${DB_PORT:-5432}
      - DB_NAME=${DB_NAME:-postgres}
      - ML_SERVICE_HOST=${ML_SERVICE_HOST:-ml_service}
      - ML_SERVICE_PORT=${ML_SERVICE_PORT:-8080}
    depends_on:
      - postgres
    networks:
      - ai_interview_net

  ml_service: &ml-service-common
    build: ml_service
    ports:
      - ${ML_SERVICE_PORT}:${ML_SERVICE_PORT}
    environment:
      - GIGACHAT_API_KEY=${GIGACHAT_API_KEY}
    networks:
      - ai_interview_net

  postgres:
    image: postgres:15
    ports: 
     - "5432:5432"
    environment:
      POSTGRES_USER: ${DB_USERNAME:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}
      POSTGRES_DB: ${DB_NAME:-postgres}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - ai_interview_net

  backend_tests:
    !!merge <<: *backend-common
    ports:
      - "8001:8001"
    profiles:
      - tests
    entrypoint: "poetry run pytest --cov-report xml:coverage.xml --cov=app tests/"
    volumes:
      - ./coverage-reports/coverage.xml:/app/coverage.xml

  ml_service_tests:
    !!merge <<: *ml-service-common
    ports:
      - "8081:8081"
    profiles:
      - tests
    entrypoint: "poetry run python -m unittest"
   
  frontend:
    build: 
      context: frontend/interview-app
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://backend:8000
      - REACT_APP_ML_API_URL=http://ml_service:${ML_SERVICE_PORT:-8080}
    volumes:
      - ./frontend/interview-app:/app
      - /app/node_modules
    depends_on:
      - backend
      - ml_service
    networks:
      - ai_interview_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3

  tg_bot:
    build: tg_bot
    environment:
      - TG_TOKEN=${TG_TOKEN}
      - ML_SERVICE_HOST=${ML_SERVICE_HOST:-ml_service}
      - ML_SERVICE_PORT=${ML_SERVICE_PORT:-8080}
    networks:
      - ai_interview_net

volumes:
  postgres_data:

networks:
  ai_interview_net:
    name: ai_interview_net
